Important guidelines and micro-instructtion for using DLC
January 24th, 2019

The original paper "Using DeepLabCut for 3D markerless pose estimation across species and behaviors" by Nath, Mathis, Chen, Patel, Bethge and Mathis is very valuable and worth reviewing before setting up the first time.

1. When creating the project:

Wake sure your working environment (current directory) is set to the base of the directory (e.g. C:\).
Make sure that within this directory, there's a folder named 'videos' with the videos you would like to train the model with.

2. Configurating the training data set:

Go to your config.yaml file in the project directory.
Under video_sets, change 'crop' to the coordinates relevant for the video.
Under bodyparts, set the names for all markers you intend to use (e.g. 'left-eye-outer_edge'). You can add new markers by adding a line.
Under numframes2pick, set the number of frames (default 20) required to train the machine with. 
Under start and stop, you may set the interval where training frames will be extracted from. This should cover diverse locations, and so recommended to be a short interval (perhaps around a blinking motion).

3. Labeling data set:

Use the extract_frames function with either uniform or kmeans extraction. Kmeans will be more useful in our case of sparse blinking, as it picks based on visual differences of the frames. Only use these in case the frame is small and interval is not long, as this is high complexity.

Before launching the labeling tool, go to the labeled-data folder, and remove the first file in the folder - as it is extracted before you crop the video.

When loading the tool, click 'load frames' and pick the folder containing all extracted frames.
Right click on the image to place a marker, and move it around with left click and drag.
In case a location is missing in a given frame - it should be skipped when labeling!


4. Evaluating the trained network:

When evaluating the network, you may set 'plotting=True' to get the images of the manually set markers (training set) and the automatic set markers (testing set). 
In addition, change 'snapshotindex' in the config file, to the snapshot integer of desire (1,2,3...). The snapshot index will determine which training snapshot is used for analyzing new videos.



~~~~~~~~ SETTING UP GPU WITH ANACONDA ON WINDOWS ~~~~~~~~~

After downloading the NVIDIA driver relevant (Check in Start>Device Manager>Display adapters) and installing it, download the NVIDIA GPU CUDA Toolkit (https://developer.nvidia.com/cuda-downloads).

In the meantime, register on NVIDIA and download the cuDNN (the deep learning library by NVIDIA).

Follow the steps provided in: 
https://medium.com/@minhplayer95/how-to-install-tensorflow-with-gpu-support-on-windows-10-with-anaconda-4e80a8beaaf0
to install and set up the CUDA environment, and TensorFlow. 

NOTE!!! Please set up a separate Anaconda environment for the GPU processing (dlc-windowsGPU) as suggested by DLC documentation (https://github.com/AlexEMG/DeepLabCut/blob/master/docs/installation.md#install-tensorflow---with-gpu-support-or-cpu-support)






Keep in mind: 
1. Training can take several days when done with CPU rather than GPU.
2. Larger frames (less cropped out) will take significantly longer to train and to analyze
3. Evaluation will take between a few minutes and an hour (CPU)

